# LLM Provider Configuration
GROQ_API_KEY=
GROQ_BASE_URL=https://api.groq.com/openai/v1
GROQ_MODEL=llama3-8b-8192

NVIDIA_API_KEY=
NVIDIA_BASE_URL=https://integrate.api.nvidia.com/v1
NVIDIA_MODEL=meta/llama3-70b-instruct

# MCP Server Configuration
MCP_SERVER_SCRIPT_PATH=D:\ds\work\workspace\git\mcp-hello\mcp_server.py
MCP_SERVER_PROTOCOL=stdio
MCP_SERVER_COMMAND=python
MCP_SERVER_TIMEOUT=30

# MCP Protocol Options: stdio, sse, http
# For SSE/HTTP protocols:
MCP_SERVER_URL=http://localhost:8080/mcp
MCP_SERVER_HEADERS={}
MCP_SSE_READ_TIMEOUT=300
MCP_SERVER_PROTOCOL=sse
MCP_SERVER_PROTOCOL=http
